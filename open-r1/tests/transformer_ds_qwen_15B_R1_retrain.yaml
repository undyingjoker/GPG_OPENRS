model:
  base_params:
    model_args: "pretrained=/mnt/workspace/cxx/opensource/open-r1/data/Qwen2.5-1.5B-Open-R1-GPG" # in fact this GRPO from scratch.
    dtype: "bfloat16"
    compile: false
  merged_weights: # Ignore this section if you are not using PEFT models
    delta_weights: false # set to True of your model should be merged with a base model, also need to provide the base model name
    adapter_weights: false # set to True of your model has been trained with peft, also need to provide the base model name
    base_model: null # path to the base_model
  generation:
#    multichoice_continuations_start_space: null # If true/false, will force multiple choice continuations to start/not start with a space. If none, will do nothing
    max_new_tokens: 4096 #32768 we use a small to control the infer speed.
    temperature: 0.6
    top_p: 0.95
